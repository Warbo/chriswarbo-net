#!/usr/bin/env bash
set -e

if PROCESS=$(pgrep ".*8666.*" | grep python)
then
    echo -e "Server already running, aborting\\n$PROCESS" 1>&2
    exit 1
fi

function ignoreInSource {
    # Things we don't expect to be reachable; mostly redirects from old URLs
    grep -v "./redirect.html"       |
    grep -v "./projects/repos"      |
    grep -v "./projects/index.html" |
    grep -v "./blog/index.html"     |
    grep -v "./data_custom"         |
    grep -v "./essays"              |
    grep -v "./posts"               |
    grep -v "./archive.html"        |
    grep -v "./index.php"           |
    grep -v "./activecode"          |
    grep -v "./arduino"             |
    grep -v "./maze"                |
    grep -v "./nixos"               |
    grep -v "./optimisation"        |
    grep -v "./plumb"               |
    grep -v "./powerplay"           |
    grep -v "./procedural"          |
    grep -v "./repos"               |
    grep -v "./turtleview"
}

function cleanup {
    echo "all_pages_reachable exiting, killing server (PID $SERVER_PID)" 1>&2
    kill "$SERVER_PID" || true
    sleep 3
    kill -9 "$SERVER_PID" || true
}

BASE="$PWD"

# shellcheck disable=SC2154
pushd "$rendered" > /dev/null

    SOURCE_CONTENT=$(find . | ignoreInSource | sort)

    # Use 'script' to fake a tty and get a "Serving HTTP..." message. Send all
    # output to ../msgs, and wait until we see the "Serving HTTP..." message
    # before continuing
    script -q /dev/null -c "python -m SimpleHTTPServer 8666" < /dev/null 2>&1 \
                                                             > "$BASE/msgs" &
    SERVER_PID="$!"

    # Delete the directory *and* kill the server when we exit
    trap cleanup EXIT

    printf "Waiting for server to start (PID %s)..." "$SERVER_PID" 1>&2

    while true
    do
        if [[ -e "$BASE/msgs" ]] && grep "^Serving HTTP.*8666" < "$BASE/msgs" \
                                                               > /dev/null
        then
            break
        fi
        printf '.' 1>&2
        sleep 1
    done

    echo "" 1>&2
    sleep 1

popd > /dev/null

# Crawl the temporary site. Unfinished pages are intentionally unreachable
# from index.html, but they should still be reachable from unfinished.html.
# Exclude /git since it's added in during deployment, and repos/ since the
# content may not be under our control.
OUTPUT=$(wget --page-requisites --mirror --no-parent --content-on-error \
              --exclude-directories="/git,/projects/repos"              \
              "http://localhost:8666"                                   \
              "http://localhost:8666/unfinished.html" 2>&1) || {
    echo "FIXME: wget exited with error code" 1>&2
}

[[ -d "localhost:8666" ]] || {
    echo "$OUTPUT" 1>&2
    echo "Didn't find 'localhost:8666' in downloaded content" 1>&2
    exit 1
}

# Compare the content we've downloaded to that in $rendered

pushd "localhost:8666" > /dev/null

    DEST_CONTENT=$(find . | sort)

popd > /dev/null

# We could use diff, but meh
ERR=0
while read -r SOURCE_FILE
do
    if ! echo "$DEST_CONTENT" | grep -Fx "$SOURCE_FILE" > /dev/null
    then
        if echo "$SOURCE_FILE" | grep "^./js/" > /dev/null
        then
            echo "Skipping unreachable Javascript file '$SOURCE_FILE'"
            continue
        fi

        echo "Rendered file '$SOURCE_FILE' wasn't reached" 1>&2
        ERR=1
    fi
done < <(echo "$SOURCE_CONTENT")

while read -r DEST_FILE
do
    echo "$SOURCE_CONTENT" | grep -Fx "$DEST_FILE" > /dev/null || {
        echo "Reached unexpected file '$DEST_FILE'" 1>&2
        ERR=1
    }
done < <(echo "$SOURCE_CONTENT")

[[ "$ERR" -eq 0 ]] || echo "$OUTPUT" 1>&2

exit "$ERR"
