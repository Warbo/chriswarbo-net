#!/usr/bin/env bash

# use relative links, rather than absolute links to chriswarbo.net

function get_urls() {
    P1="not(contains(@class, 'author'))"
    P2="not(contains(@rel,   'author'))"
    P3="not(contains(@rel,   'me'))"
    PRED="[$P1 and $P2 and $P3]"
    xidel - -s --extract "//*$PRED/@href" < "$1"
    xidel - -s --extract "//*$PRED/@src"  < "$1"
}

function get_files {
    # shellcheck disable=SC2154
    find "$rendered" -name "*.html"
}

ERR=0
while read -r FILE
do
    if echo "$FILE" | grep "projects/repos/" > /dev/null
    then
        # Skip repos, since their READMEs might contain anything
        continue
    fi

    # Strip out anything after a '/', since we only care about the domain name.
    # To make this work, we also have to strip out the protocol (e.g. http://)
    # since that obviously contains a '/'.
    if get_urls "$FILE" | sed -e 's@^.*://@@g' -e 's@/.*$@@g' |
                          grep "chriswarbo\.net"
    then
        echo "Found absolute links to chriswarbo.net in '$FILE'" 1>&2
        ERR=1
    fi
    if get_urls "$FILE" | grep "^/"
    then
        echo "Found link to root (/) in '$FILE'" 1>&2
        ERR=1
    fi
done < <(get_files)

exit "$ERR"
